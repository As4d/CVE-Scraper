from bs4 import BeautifulSoup
import requests, re, pprint

cveIDNumber = []
cvssScore = []
confidentialityImpact = []
integrityImpact = []
availibilityImpact = []
accessComplexity = []
authentication = []
gainedAccess = []
vulnType = []
exploitAvailible = []


def getSoupHTML(url):
	response = requests.get(url)
	html = response.content
	soup = BeautifulSoup(html, "html.parser")
	return soup


def getCVEIds(soup, cveArray):
	table = soup.find("table", attrs={"class", "searchresults"})
	for a in table.find_all("a", href=True):
		m = re.search("CVE-\d{4}-\d{4,7}", a["href"])
		if m:
			cveArray.append(m.group(0))


def getCVEPages(soup):
	cveIDPages = []
	items = soup.find_all("div", class_="paging")
	for item in items:
		links = item.find_all("a")
		for link in links:
			cveIDPages.append("http://www.cvedetails.com/" + str(link["href"]))

	return cveIDPages


def getCVEDetails(cveid=""):
	cveUrl = "http://www.cvedetails.com/cve/{}/".format(cveid)
	response = requests.get(cveUrl)
	cveHtml = response.content
	soup = BeautifulSoup(cveHtml, "html.parser")
	if soup == "":
		return
	cveIDNumber.append(cveid)
	table = soup.find(id="vulnprodstable")
	cvssTable = soup.find(id="cvssscorestable")
	cvssData = []
	for row in cvssTable.findAll("tr"):
		cols = row.findAll("td")
		for i in range(len(cols)):
			cvssData.append(cols[i].text.strip())
	print(cvssData)
	for i in range(7):
		print(cvssData[i])
	cvssScore.append(cvssData[0])
	scrapedData = [cvssData[i].split("\n")[0] for i in range(1, 7)]
	confidentialityImpact.append(scrapedData[0])
	integrityImpact.append(scrapedData[1])
	availibilityImpact.append(scrapedData[2])
	accessComplexity.append(scrapedData[3])
	authentication.append(scrapedData[4])
	gainedAccess.append(scrapedData[5])
	vulnType.append(cvssData[7])
	print(cvssData[0], scrapedData, cvssData[7])
	print(
		cveIDNumber,
		cvssScore,
		confidentialityImpact,
		integrityImpact,
		availibilityImpact,
		accessComplexity,
		authentication,
		gainedAccess,
		vulnType,
		exploitAvailible,
	)


def main():

	url = "https://www.cvedetails.com/vulnerability-list/vendor_id-26/product_id-32238/version_id-677477.html"
	print("Scraping {}".format((url)))
	soupObject = getSoupHTML(url)
	cvePagesArray = getCVEPages(soupObject)
	cveArray = []
	for cvePage in cvePagesArray:
		soupObject = getSoupHTML(cvePage)
		getCVEIds(soupObject, cveArray)

	count = 0
	for cve in cveArray:
		try:

			count += 1
			print(
				"[+] Fetching Data for CVE ID: {}. {}/{}".format(
					cve, str(count), str(len(cveArray))
				)
			)
			getCVEDetails(cve)

		except:
			print("[-] Failed to Fetch Data for CVE ID: {}.".format(cve))

		if count == 1:
			break  # test


if __name__ == "__main__":
	main()
